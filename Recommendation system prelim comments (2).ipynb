{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a50b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b87e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = \"C:/Users/scvch/Documents/Industry_Practicum/Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b382ea",
   "metadata": {},
   "source": [
    "## Events Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c02620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(loc):\n",
    "    ## Reading in the Events data and changing EventTimestamp to appropriate date format\n",
    "    Events = pd.read_csv(loc + \"Events.txt\",sep = \"\\t\")\n",
    "    Events['EventTimestamp'] = pd.to_datetime(Events['EventTimestamp']).dt.date\n",
    "    #Events['ModifyDate'] = pd.to_datetime(Events['ModifyDate']).dt.date\n",
    "    #Events['JoinedDate'] = pd.to_datetime(Events['JoinedDate']).dt.date\n",
    "\n",
    "    # Creating EventTimestamp for 2021 and changing to appropriate date format\n",
    "    Event_sep_2021 = Events[Events['EventTimestamp'] <= datetime.strptime('2021-09-01',\"%Y-%m-%d\").date()]\n",
    "    #Events = pd.read_csv(loc + \"Events.txt\",sep = \"\\t\",low_memory = False,skiprows = 1000000,nrows = 3000000)\n",
    "\n",
    "\n",
    "\n",
    "    ## Reading in the Requests data and changing RequestDate to appropriate format\n",
    "    Requests = pd.read_csv(loc + \"Requests.txt\",sep = \"\\t\")\n",
    "    Requests['RequestDate'] = pd.to_datetime(Requests['RequestDate']).dt.date\n",
    "\n",
    "    ## Reading in the Request Resorts data\n",
    "    Request_Resorts = pd.read_csv(loc + \"Request Resorts.txt\",sep = \"\\t\")\n",
    "\n",
    "\n",
    "    ## Reading in the request_offers data and changing OfferDate to appropriate format\n",
    "    Request_offers = pd.read_csv(loc + \"Request Offers.txt\",sep = \"\\t\")\n",
    "    Request_offers['OfferDate'] = pd.to_datetime(Request_offers['OfferDate']).dt.date\n",
    "\n",
    "\n",
    "    ## Reading in the Inventory data and using Exchange suppliedAs, Member purchaser base type, and converting depositDate to date date format\n",
    "    Inventory = pd.read_csv(loc + \"Inventory.txt\",sep = \"\\t\")\n",
    "    Inventory = Inventory[Inventory['suppliedAs'] == 'Exchange']\n",
    "    Inventory = Inventory[Inventory['purchaserbaseType'] == 'MEMBER']\n",
    "    Inventory['depositDate'] = pd.to_datetime(Inventory['depositDate']).dt.date\n",
    "    \n",
    "    df_Resort_Details=pd.read_csv(loc + 'Resort Details.txt', delimiter=\"\\t\")\n",
    "    #df_Resort_Details.head()\n",
    "    df_Attributes=pd.read_csv(loc + 'Attributes.txt', delimiter=\"\\t\")\n",
    "    #df_Attributes.head()\n",
    "    df_Resort_Other_Attributes=pd.read_csv(loc + 'Resort Other Attributes.txt', delimiter=\"\\t\")\n",
    "    df=df_Resort_Other_Attributes\n",
    "    \n",
    "    return Events,Requests,Request_Resorts,Request_offers,Inventory,df_Resort_Details,df_Attributes,df_Resort_Other_Attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cfc0d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scvch\\anaconda4\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "Events,Requests,Request_Resorts,Request_offers,Inventory,df_Resort_Details,df_Attributes,df_Resort_Other_Attributes = read_data(loc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e5148",
   "metadata": {},
   "source": [
    "## Request and search data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289f5c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scvch\\anaconda4\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "Accounts = pd.read_csv(loc + \"Account.txt\",sep = \"\\t\")\n",
    "Accounts['AccountStatus'].fillna('Active',inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78fe1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a4538f7",
   "metadata": {},
   "source": [
    "## Resort Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498731b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Unique ResourtID, AttrType and AttrID values\n",
    "ls_resort_id = list(df_Resort_Other_Attributes['ResortID'].unique())\n",
    "ls_resort_id\n",
    "ls_attr_type = list(df_Resort_Other_Attributes['AttrType'].unique())\n",
    "ls_attr_type\n",
    "ls_attr_id = list(df_Resort_Other_Attributes['AttrID'].unique())\n",
    "#ls_attr_id\n",
    "\n",
    "\n",
    "# Create data final dictionary and put Resort ID and AttrType 1 dimensional vectors\n",
    "data_final={}\n",
    "data_final['Resort ID']=[]\n",
    "data_final['Attr Type']=[]\n",
    "for i in ls_attr_id:\n",
    "    data_final[i]=[]\n",
    "    \n",
    "    \n",
    "for resort in ls_resort_id:\n",
    "    #print (resort)\n",
    "    # where ResortID = resort and AttrType = type, appending them accordingly to those variables and creating a list with unique AttributeIDs\n",
    "    for type in ls_attr_type:\n",
    "        df_temp=df_Resort_Other_Attributes[(df_Resort_Other_Attributes['ResortID']==resort) & (df_Resort_Other_Attributes['AttrType']==type)]\n",
    "        data_final['Attr Type'].append(type)\n",
    "        data_final['Resort ID'].append(resort)\n",
    "        ls_id=list(df_temp['AttrID'].unique())\n",
    "        # Appending 1 to data_final vector and creating ls_id complement\n",
    "        for j in ls_id:\n",
    "            data_final[j].append(1)\n",
    "        ls_id_complement=list(set(ls_attr_id)-set(ls_id))\n",
    "        # Append 0 to data_final vector for every k in lis_id_complement\n",
    "        for k in ls_id_complement:\n",
    "            data_final[k].append(0) \n",
    "\n",
    "df_final=pd.DataFrame(data_final)\n",
    "#df_final1=df_final.set_index(['Resort ID','Attr Type',df.groupby(['Resort_ID']).cumcount()+1]).unstack().sort_index(level=1,axis=1)\n",
    "df_final1=df_final.set_index(['Resort ID','Attr Type']).unstack().sort_index(level=1)\n",
    "                             \n",
    "#df_out = df.set_index(['IndividualID','DayID',df.groupby(['IndividualID','DayID']).cumcount()+1]).unstack().sort_index(level=1, axis=1)\n",
    "#df_final.columns = df_final.columns.map('{0[0]}_{0[1]}'.format)\n",
    "#df_final1.reset_index()\n",
    "col=list(df_final1.columns)\n",
    "final_col=[str(i) for i in col]\n",
    "final_col\n",
    "df_final1.columns = final_col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435499b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4088c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(60, 9)</th>\n",
       "      <th>(60, 11)</th>\n",
       "      <th>(60, 13)</th>\n",
       "      <th>(46, 9)</th>\n",
       "      <th>(46, 11)</th>\n",
       "      <th>(46, 13)</th>\n",
       "      <th>(62, 9)</th>\n",
       "      <th>(62, 11)</th>\n",
       "      <th>(62, 13)</th>\n",
       "      <th>(14, 9)</th>\n",
       "      <th>...</th>\n",
       "      <th>(4049, 13)</th>\n",
       "      <th>(831, 9)</th>\n",
       "      <th>(831, 11)</th>\n",
       "      <th>(831, 13)</th>\n",
       "      <th>(1195, 9)</th>\n",
       "      <th>(1195, 11)</th>\n",
       "      <th>(1195, 13)</th>\n",
       "      <th>(4061, 9)</th>\n",
       "      <th>(4061, 11)</th>\n",
       "      <th>(4061, 13)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resort ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$99BVOU</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZJHH</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZURICH</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZWCARB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZWTROUT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYLH</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9178 rows × 540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           (60, 9)  (60, 11)  (60, 13)  (46, 9)  (46, 11)  (46, 13)  (62, 9)  \\\n",
       "Resort ID                                                                      \n",
       "$99BVOU          0         0         0        0         0         0        0   \n",
       "10026            0         0         0        0         0         0        0   \n",
       "10101            0         0         0        0         0         0        0   \n",
       "10161            0         0         0        0         0         0        0   \n",
       "1366             0         0         0        0         0         0        0   \n",
       "...            ...       ...       ...      ...       ...       ...      ...   \n",
       "ZJHH             1         0         0        0         0         0        0   \n",
       "ZURICH           0         0         0        0         0         0        0   \n",
       "ZWCARB           0         0         0        1         0         0        0   \n",
       "ZWTROUT          0         0         0        0         0         0        0   \n",
       "ZYLH             0         0         0        0         0         0        1   \n",
       "\n",
       "           (62, 11)  (62, 13)  (14, 9)  ...  (4049, 13)  (831, 9)  (831, 11)  \\\n",
       "Resort ID                               ...                                    \n",
       "$99BVOU           0         0        0  ...           0         0          0   \n",
       "10026             0         0        0  ...           0         0          0   \n",
       "10101             0         0        0  ...           0         0          0   \n",
       "10161             0         0        0  ...           0         0          0   \n",
       "1366              0         0        0  ...           0         0          0   \n",
       "...             ...       ...      ...  ...         ...       ...        ...   \n",
       "ZJHH              0         0        1  ...           0         0          0   \n",
       "ZURICH            0         0        0  ...           0         0          0   \n",
       "ZWCARB            0         0        1  ...           0         0          0   \n",
       "ZWTROUT           0         0        1  ...           0         0          0   \n",
       "ZYLH              0         0        1  ...           0         0          0   \n",
       "\n",
       "           (831, 13)  (1195, 9)  (1195, 11)  (1195, 13)  (4061, 9)  \\\n",
       "Resort ID                                                            \n",
       "$99BVOU            0          0           0           0          0   \n",
       "10026              0          0           0           0          0   \n",
       "10101              0          0           0           0          0   \n",
       "10161              0          0           0           0          0   \n",
       "1366               0          0           0           0          0   \n",
       "...              ...        ...         ...         ...        ...   \n",
       "ZJHH               0          0           0           0          0   \n",
       "ZURICH             0          0           0           0          0   \n",
       "ZWCARB             0          0           0           0          0   \n",
       "ZWTROUT            0          0           0           0          0   \n",
       "ZYLH               0          0           0           0          0   \n",
       "\n",
       "           (4061, 11)  (4061, 13)  \n",
       "Resort ID                          \n",
       "$99BVOU             0           0  \n",
       "10026               0           0  \n",
       "10101               0           0  \n",
       "10161               0           0  \n",
       "1366                0           0  \n",
       "...               ...         ...  \n",
       "ZJHH                0           0  \n",
       "ZURICH              0           0  \n",
       "ZWCARB              0           0  \n",
       "ZWTROUT             0           0  \n",
       "ZYLH                0           0  \n",
       "\n",
       "[9178 rows x 540 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df9dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aef6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Create df_final as dataframe\n",
    "#df_final=pd.DataFrame(data_final)\n",
    "resort_dt = df_final1\n",
    "\n",
    "# Compute cosine similarity wth resort tables\n",
    "cosine_sim = linear_kernel(resort_dt, resort_dt)\n",
    "# show cosine similarity shape\n",
    "\n",
    "# reset Index for Resort table\n",
    "resort_new = resort_dt.reset_index()\n",
    "\n",
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(resort_new.index,index = resort_new['Resort ID']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db5898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9dcb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create recommendation of similar resourts via movie titles\n",
    "    \n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "\n",
    "    if str(title) in resort_new['Resort ID'].unique() : \n",
    "        idx = indices[title]\n",
    "\n",
    "        # Get the pairwsie similarity scores of all resorts with the resort\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "        # Sort the resorts based on the similarity scores\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get the resorts of the 5 most similar resorts\n",
    "        sim_scores = sim_scores[1:6]\n",
    "        \n",
    "        # Get the resort indices\n",
    "        resort_indices = [i[0] for i in sim_scores]\n",
    "        return list(resort_new['Resort ID'].iloc[resort_indices])\n",
    "    else :\n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1331f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81979446",
   "metadata": {},
   "source": [
    "### Factors \n",
    "\n",
    "1. Number of searches (1,0.5,0.25,0.125)\n",
    "2. Number of Requests\n",
    "3. Number of Bookings\n",
    "4. Number of cancellations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80312801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2819e6",
   "metadata": {},
   "source": [
    "## Bookings interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c715748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using those Events where something was purchased, create Bookings_new by inner joining Bookings with Inventory Tables\n",
    "Bookings = Events[(Events['eventName'] == 'Purchased Something')]\n",
    "Bookings_new = pd.merge(Bookings,Inventory,left_on = 'DepositID',right_on = 'depositId',how = 'inner')\n",
    "Bookings_new = Bookings_new[['AccountID','EventTimestamp','resortId']]\n",
    "#Bookings_new.groupby(\"AccountID\")[\"EventTimestamp\"].rank(ascending=0,method='dense')\n",
    "\n",
    "# Create the days_since variable as number of days since booking happened\n",
    "Bookings_new['days_since'] = datetime.strptime('2022-01-01',\"%Y-%m-%d\").date() - Bookings_new['EventTimestamp']\n",
    "Bookings_new['days_since'] = Bookings_new['days_since'].dt.days\n",
    "\n",
    "# Rank new Bookings by days since booking happened\n",
    "Bookings_new['rank'] = Bookings_new.groupby(\"AccountID\")[\"days_since\"].rank(ascending=1,method='dense')\n",
    "Bookings_new[\"Bookings\"] = 1/Bookings_new[\"rank\"]\n",
    "Bookings_new = Bookings_new[['AccountID','resortId','Bookings']].groupby(['AccountID','resortId']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089ff2f",
   "metadata": {},
   "source": [
    "## Request Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c5fb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using those Events where member request was palced, create Requests_new by inner joining Requests with request_resorts Tables\n",
    "Requests = Events[(Events['eventName'] == 'Member Request Placed')]\n",
    "Request_Resorts.rename(columns = {'ResortID':'resortId'}, inplace = True)\n",
    "Requests_new = pd.merge(Requests,Request_Resorts,left_on = 'RequestID',right_on = 'RequestID',how = 'inner')\n",
    "Requests_new = Requests_new[['AccountID','EventTimestamp','resortId']]\n",
    "#Bookings_new.groupby(\"AccountID\")[\"EventTimestamp\"].rank(ascending=0,method='dense')\n",
    "\n",
    "# Create the days_since variable as number of days since requests happened\n",
    "Requests_new['days_since'] = datetime.strptime('2022-01-01',\"%Y-%m-%d\").date() - Requests_new['EventTimestamp']\n",
    "Requests_new['days_since'] = Requests_new['days_since'].dt.days\n",
    "\n",
    "# Rank new Requests by days since request was made\n",
    "Requests_new['rank'] = Requests_new.groupby(\"AccountID\")[\"days_since\"].rank(ascending=1,method='dense')\n",
    "Requests_new[\"Requests\"] = 1/Requests_new[\"rank\"]\n",
    "Requests_new = Requests_new[['AccountID','resortId','Requests']].groupby(['AccountID','resortId']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f989c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bfdda65",
   "metadata": {},
   "source": [
    "## Search Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3eddf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain by member search availability, innher join Search and Request_Resorts tables\n",
    "Search = Events[(Events['eventName'] == 'Member Search Availability')]\n",
    "Search_new = pd.merge(Search,Request_Resorts,left_on = 'RequestID',right_on = 'RequestID',how = 'inner')\n",
    "Search_new = Search_new[['AccountID','EventTimestamp','resortId']]\n",
    "#Bookings_new.groupby(\"AccountID\")[\"EventTimestamp\"].rank(ascending=0,method='dense')\n",
    "\n",
    "# Create the days_since variable as number of days since member availability was searched\n",
    "Search_new['days_since'] = datetime.strptime('2022-01-01',\"%Y-%m-%d\").date() - Search_new['EventTimestamp']\n",
    "Search_new['days_since'] = Search_new['days_since'].dt.days\n",
    "Search_new['rank'] = Search_new.groupby(\"AccountID\")[\"days_since\"].rank(ascending=1,method='dense')\n",
    "\n",
    "# Rank new searches by days since search was made (recency of search)\n",
    "Search_new[\"searches\"] = 1/Search_new[\"rank\"]\n",
    "Search_new = Search_new[['AccountID','resortId','searches']].groupby(['AccountID','resortId']).sum().reset_index()\n",
    "Search_new.rename(columns = {'Requests':'Searches'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db8d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5ebdba2",
   "metadata": {},
   "source": [
    "## Cancellation requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd75eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtained by member request Placed, inner join Request_offers and Request_Resorts tables\n",
    "cancels_data = pd.merge(Request_offers,Request_Resorts,on = 'RequestID')\n",
    "cancels_data = cancels_data[cancels_data['OfferStatus'] == 'CANCELLED']\n",
    "Requests = Events[(Events['eventName'] == 'Member Request Placed')]\n",
    "\n",
    "# Further inner join Requests and Cancels_data tables with AccountID, EventTimestamp and resortId variables\n",
    "cancels_new = pd.merge(Requests,cancels_data,left_on = 'RequestID',right_on = 'RequestID',how = 'inner')\n",
    "cancels_new = cancels_new[['AccountID','EventTimestamp','resortId']]\n",
    "#Bookings_new.groupby(\"AccountID\")[\"EventTimestamp\"].rank(ascending=0,method='dense')\n",
    "\n",
    "# Create the days_since variable as number of days since a request was cancelled, subtracted from when a request was placed\n",
    "cancels_new['days_since'] = datetime.strptime('2022-10-01',\"%Y-%m-%d\").date() - cancels_new['EventTimestamp']\n",
    "cancels_new['days_since'] = cancels_new['days_since'].dt.days\n",
    "\n",
    "# Rank by recency of request cancelled\n",
    "cancels_new['rank'] = cancels_new.groupby(\"AccountID\")[\"days_since\"].rank(ascending=1,method='dense')\n",
    "cancels_new[\"Cancels\"] = -1/cancels_new[\"rank\"]\n",
    "cancels_new = cancels_new[['AccountID','resortId','Cancels']].groupby(['AccountID','resortId']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b837114",
   "metadata": {},
   "source": [
    "### Making all the accounts interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bf8df39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scvch\\anaconda4\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reading Account table, and converting JoinedDate and ModifyDate to date formats\n",
    "Accounts = pd.read_csv(loc + \"Account.txt\",sep = \"\\t\")\n",
    "Accounts['AccountStatus'].fillna('Active',inplace = True)\n",
    "Accounts['JoinedDate'] = pd.to_datetime(Accounts['JoinedDate']).dt.date\n",
    "Accounts['ModifyDate'] = pd.to_datetime(Accounts['ModifyDate']).dt.date\n",
    "\n",
    "# Reading Resort Details, chainging updateDate column to date format and dropping 'territoryId','territory','AccountId','mapDestOfficeKey','busDevUserId','busDevUser','daeOptions','excludeFromAvailability' columns\n",
    "resort = pd.read_csv(loc + \"Resort Details.txt\",sep = \"\\t\")\n",
    "resort = resort.drop(columns = ['territoryId','territory','AccountId','mapDestOfficeKey','busDevUserId','busDevUser','daeOptions','excludeFromAvailability'])\n",
    "resort['updatedDate'] = pd.to_datetime(resort['updatedDate']).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15f5eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting key as 0 for Accounts and Resort\n",
    "Accounts = Accounts[['accountid']]\n",
    "Accounts['key'] = 0\n",
    "resort = resort[['resortId']]\n",
    "resort['key'] = 0\n",
    "\n",
    "\n",
    "# Outer join merging new Bookings with new requests,new searches and later new cancellations tables to crete all interactions\n",
    "dt = Bookings_new.merge(Requests_new,how = 'outer',on = ['AccountID','resortId']).merge(Search_new,how = 'outer',on = ['AccountID','resortId'])\n",
    "\n",
    "dt = dt.merge(cancels_new,how = 'outer',on = ['AccountID','resortId'])\n",
    "dt.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abf532b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountID</th>\n",
       "      <th>resortId</th>\n",
       "      <th>Bookings</th>\n",
       "      <th>Requests</th>\n",
       "      <th>searches</th>\n",
       "      <th>Cancels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303</td>\n",
       "      <td>CEDL</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1303</td>\n",
       "      <td>SHEW</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1348</td>\n",
       "      <td>CAPW</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1348</td>\n",
       "      <td>LAKE</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1348</td>\n",
       "      <td>LAKS</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922542</th>\n",
       "      <td>7126282</td>\n",
       "      <td>SILS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922543</th>\n",
       "      <td>7126292</td>\n",
       "      <td>MISTY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922544</th>\n",
       "      <td>7126292</td>\n",
       "      <td>MPKLOP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922545</th>\n",
       "      <td>7126292</td>\n",
       "      <td>MSSA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922546</th>\n",
       "      <td>7126292</td>\n",
       "      <td>R_101001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922547 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AccountID  resortId  Bookings  Requests  searches  Cancels\n",
       "0            1303      CEDL  1.000000  0.000000       0.5      0.0\n",
       "1            1303      SHEW  5.000000  1.000000       2.0      0.0\n",
       "2            1348      CAPW  0.125000  0.333333       0.0      0.0\n",
       "3            1348      LAKE  0.166667  0.333333       0.0      0.0\n",
       "4            1348      LAKS  1.500000  0.000000       3.0      0.0\n",
       "...           ...       ...       ...       ...       ...      ...\n",
       "922542    7126282      SILS  0.000000  0.000000       4.0      0.0\n",
       "922543    7126292     MISTY  0.000000  0.000000       1.0      0.0\n",
       "922544    7126292    MPKLOP  0.000000  0.000000       1.0      0.0\n",
       "922545    7126292      MSSA  0.000000  0.000000       7.0      0.0\n",
       "922546    7126292  R_101001  0.000000  0.000000       8.0      0.0\n",
       "\n",
       "[922547 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b8e9ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-c903ddafe907>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_content_recommendations['recommendations'] = dt_content_recommendations['resortId'].apply(get_recommendations)\n"
     ]
    }
   ],
   "source": [
    "# creating interaction data with more weightage to bookings and cancellations\n",
    "dt['interaction'] = 5*dt['Bookings'] + dt['Requests'] + dt['searches'] + 5*dt['Cancels']\n",
    "\n",
    "# creating resort_ranking data by grouping by AccountID and ranking interaction\n",
    "dt['resort_ranking'] = dt.groupby(['AccountID'])['interaction'].rank(ascending=0,method='dense')\n",
    "\n",
    "# creating Content recommendations for 1 or 2\n",
    "dt_content_recommendations = dt[(dt['resort_ranking']==1) | (dt['resort_ranking']==2) ]\n",
    "\n",
    "\n",
    "# apply get_recomemndations variable to resortId\n",
    "dt_content_recommendations['recommendations'] = dt_content_recommendations['resortId'].apply(get_recommendations)\n",
    "\n",
    "\n",
    "\n",
    "# Add recommendations table and predicted_accounts table to existing master attribute dataset for Contet_recommendations and predicted_accounts\n",
    "dt_content_recommendations = pd.read_csv(loc + 'recommendations.csv' )\n",
    "predicted_accounts = pd.read_csv(loc + 'predicted_accounts.csv' )\n",
    "\n",
    "\n",
    "# Created predicted_accounts table\n",
    "predicted_accounts.columns = ['index','account_id']\n",
    "predicted_accounts = predicted_accounts[['account_id']] \n",
    "#Master_data =  pd.read_csv(loc + 'Master_data.csv' )\n",
    "\n",
    "\n",
    "# Set up train start data as Jan 2022 and a season length of 3 months for training data\n",
    "train_start_date = '2022-01-01'\n",
    "season_length = 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f99a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bf7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c266f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scvch\\anaconda4\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Created s date variable, offsetting for 3 months\n",
    "s = datetime.strptime(train_start_date,\"%Y-%m-%d\").date() - pd.DateOffset(months = season_length)\n",
    "s = s.date()\n",
    "\n",
    "## Reading in the account type data and using only Member status\n",
    "Account_type = pd.read_csv(loc + \"Account Type.txt\",sep = \"\\t\")\n",
    "Account_type = Account_type[Account_type['BaseType'] == 'MEMBER']\n",
    "\n",
    "## Reading in the accounts data and using only Active status\n",
    "Accounts = pd.read_csv(loc + \"Account.txt\",sep = \"\\t\")\n",
    "Accounts['AccountStatus'].fillna('Active',inplace = True)\n",
    "\n",
    "## Converting JoinedDate and ModifyDate columns to appropriate format\n",
    "Accounts['JoinedDate'] = pd.to_datetime(Accounts['JoinedDate']).dt.date\n",
    "Accounts['ModifyDate'] = pd.to_datetime(Accounts['ModifyDate']).dt.date\n",
    "Accounts = pd.merge(Accounts,Account_type,on = 'AccountType',how = 'inner')\n",
    "\n",
    "# Accounted for Time period for JoinedDate, and created no. of Membership days\n",
    "Accounts = Accounts[Accounts['JoinedDate'] < s] \n",
    "Accounts['Membership days'] = s - Accounts['ModifyDate']  \n",
    "Accounts['Membership days'] = Accounts['Membership days'].dt.days\n",
    "Accounts = Accounts[Accounts['AccountStatus'] == 'Active']\n",
    "\n",
    "# Inner joined Accounts with Account_type and Account and Account_Members and Events to get Account and Event Members tables\n",
    "Account_Members = pd.merge(Accounts,Account_type,how = 'inner',left_on = 'AccountType',right_on = 'AccountType')[[\"accountid\"]]\n",
    "Event_Members = pd.merge(Account_Members,Events,how = 'inner',left_on = 'accountid',right_on = 'AccountID')\n",
    "\n",
    "## Calculating Events for season 9 in the 3 month period for event where something was purchased (dropping duplicates)\n",
    "Events_s9 = Event_Members[(Event_Members['EventTimestamp'] > s) & (Event_Members['EventTimestamp'] < s + pd.DateOffset(months=3)) ]\n",
    "Events_s9 = Events_s9[Events_s9['eventName']=='Purchased Something'].drop_duplicates()\n",
    "Events_s9['response'] = 1 \n",
    "\n",
    "# dropping duplicates from account id for all_accounts, and accountid and response for response variable\n",
    "all_accounts = Event_Members[['accountid']].drop_duplicates()\n",
    "response = Events_s9[['accountid','response']].drop_duplicates()\n",
    "\n",
    "# Setting up response table by merging all_accounts and response, filling null values with 0, and making into integer type\n",
    "response = pd.merge(all_accounts,response,how = 'left',left_on = 'accountid',right_on = 'accountid')\n",
    "response['response'].fillna(0,inplace = True)\n",
    "response['response']= response['response'].astype(int)\n",
    "\n",
    "\n",
    "# inner join Accounts and response tables\n",
    "Accounts = pd.merge(Accounts,response,on = 'accountid',how = 'inner') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c08348fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4696"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number where there are responses\n",
    "sum(response['response']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88ae38c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AccountID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-d904925ebc4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Inner join final_accounts onto content recommendations table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdt_content_recommendations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_accounts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdt_content_recommendations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'inner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accountid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'AccountID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 74\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AccountID'"
     ]
    }
   ],
   "source": [
    "# create final accounts as predicted account - current accounts where there is response\n",
    "accounts = response[response['response'] == 1]['accountid']\n",
    "final_accounts = set(predicted_accounts['account_id']) - set(accounts)\n",
    "final_accounts = pd.DataFrame(final_accounts)\n",
    "final_accounts.columns = ['accountid']\n",
    "#final_accounts\n",
    "#dt_content_recommendations\n",
    "\n",
    "# Inner join final_accounts onto content recommendations table\n",
    "dt_content_recommendations = pd.merge(final_accounts,dt_content_recommendations, how = 'inner', left_on = 'accountid',right_on = 'AccountID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a701b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5969f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtained number of times a resort was booked and merged final_accounts to it\n",
    "resorts_booked = Events[Events['eventName']== 'Purchased Something']\n",
    "\n",
    "resorts_booked = pd.merge(final_accounts,resorts_booked,how = 'inner',left_on = 'accountid', right_on = 'AccountID')\n",
    "\n",
    "# Added Inventory data to current dataset where members were given exchange. 'depositDate' format was also changed\n",
    "Inventory = pd.read_csv(loc + \"Inventory.txt\",sep = \"\\t\")\n",
    "Inventory = Inventory[Inventory['suppliedAs'] == 'Exchange']\n",
    "Inventory = Inventory[Inventory['purchaserbaseType'] == 'MEMBER']\n",
    "Inventory['depositDate'] = pd.to_datetime(Inventory['depositDate']).dt.date\n",
    "\n",
    "# only kept AccountID and DepositID in resorts_booked, and changed DepositID to float type\n",
    "resorts_booked = resorts_booked[['AccountID','DepositID']]\n",
    "resorts_booked['DepositID'] = resorts_booked['DepositID'].astype('float')\n",
    "\n",
    "# only kept resortId and DepositId in resorts_booked, and changed DepositId to float type\n",
    "Inventory = Inventory[['depositId','resortId']]\n",
    "Inventory['depositId'] = Inventory['depositId'].astype('float')\n",
    "\n",
    "#Inner joined Inventory and resorts_booked\n",
    "resorts_booked = pd.merge(Inventory,resorts_booked,left_on = 'depositId',right_on = 'DepositID' , how = 'inner')\n",
    "\n",
    "resorts_booked\n",
    "\n",
    "# Numbered resport_booked's idx variable by AccountID, pivoted and replaced null values\n",
    "resorts_booked['idx'] = resorts_booked.groupby('AccountID').cumcount()\n",
    "resorts_booked = resorts_booked.pivot(index = 'AccountID',columns='idx')[['resortId']]\n",
    "resorts_booked = resorts_booked.fillna('')\n",
    "\n",
    "# Started booked_resorts, a 1 dimensional vector\n",
    "booked_resorts = []\n",
    "\n",
    "freq = int(len(resorts_booked.values.flatten().tolist())/len(resorts_booked))\n",
    "\n",
    "# rearranging resorts booked values in the table\n",
    "for i in range(0,len(resorts_booked.values.flatten().tolist()),freq ):    \n",
    "    booked_resorts.append(resorts_booked.values.flatten().tolist()[i:i+freq])\n",
    "    \n",
    "# Resetting index for resorts_booked\n",
    "resorts_booked['booked_resorts'] = booked_resorts\n",
    "resorts_booked = resorts_booked['booked_resorts'].reset_index()\n",
    "\n",
    "#dt_content_recommendations['recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37a2098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "str_list = lambda x : x.translate(str.maketrans('', '', string.punctuation)).split(' ')\n",
    "\n",
    "# changing recommendations column to string, and apply str_list\n",
    "dt_content_recommendations['recommendations'] = dt_content_recommendations['recommendations'].astype('str')\n",
    "dt_content_recommendations['recommendations'] = dt_content_recommendations['recommendations'].apply(str_list)\n",
    "\n",
    "# inner joining resorts_booked to our content recommendations data\n",
    "dt_content_recommendations = pd.merge(resorts_booked,dt_content_recommendations,how = 'inner',on = 'AccountID')\n",
    "\n",
    "\n",
    "def removing_past_resorts(x,y):\n",
    "    return set(x)-set(y)\n",
    "\n",
    "# looping such that we remove past resorts from our recommendations\n",
    "dt_content_recommendations['new_recommendations'] = dt_content_recommendations.apply(lambda x: removing_past_resorts(x['recommendations'], x['booked_resorts']), axis=1)\n",
    "dt_content_recommendations = dt_content_recommendations[['AccountID','new_recommendations']]\n",
    "dt_content_recommendations['idx'] = dt_content_recommendations.groupby('AccountID').cumcount()\n",
    "dt_content_recommendations = dt_content_recommendations.pivot(index = 'AccountID',columns='idx')[['new_recommendations']]\n",
    "dt_content_recommendations = dt_content_recommendations.iloc[:,0:2].reset_index()\n",
    "dt_content_recommendations.columns = ['Account_id','Set1_recommendation','Set2_recommendation']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77e95f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account_id</th>\n",
       "      <th>Set1_recommendation</th>\n",
       "      <th>Set2_recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26018</td>\n",
       "      <td>{IA, R3735, BCOM, R0653, 3936}</td>\n",
       "      <td>{IA, CASB, R3683, R2826, SUNP}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26030</td>\n",
       "      <td>{IA, LAKS, BUSS, BELL, MANS}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26098</td>\n",
       "      <td>{TWVC, IA, CABA, R3683, R2084}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26165</td>\n",
       "      <td>{IA, LAKS, BUSS, BELL, MANS}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26202</td>\n",
       "      <td>{EMET, IA, NEPC, SHEWR, CUMB}</td>\n",
       "      <td>{IA, LAKS, BUSS, BELL, MANS}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13631</th>\n",
       "      <td>7117863</td>\n",
       "      <td>{R2989, EW8677, R3574, R3683, R2414}</td>\n",
       "      <td>{EW5623, EW7053, EW5856, EW3880, EW4445}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13632</th>\n",
       "      <td>7119649</td>\n",
       "      <td>{IA, R3668, MOOR, R100142, MOOR3}</td>\n",
       "      <td>{EMET, BELL, IA, MOOR3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13633</th>\n",
       "      <td>7120107</td>\n",
       "      <td>{EMET, IA, NEPC, R3683, NEPCSPA}</td>\n",
       "      <td>{EMET, R2395, BFRC, R2734, MGWC}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13634</th>\n",
       "      <td>7121658</td>\n",
       "      <td>{IA, MPNGWE, EW725, DRCASP, R3683}</td>\n",
       "      <td>{R0508, R0899, R0090, MIO, HILD}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13635</th>\n",
       "      <td>7122285</td>\n",
       "      <td>{R2047, R1287, R1731, R1544, R1873}</td>\n",
       "      <td>{R0579, R0397, R0889, R100269, R0745}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13636 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Account_id                   Set1_recommendation  \\\n",
       "0           26018        {IA, R3735, BCOM, R0653, 3936}   \n",
       "1           26030          {IA, LAKS, BUSS, BELL, MANS}   \n",
       "2           26098        {TWVC, IA, CABA, R3683, R2084}   \n",
       "3           26165          {IA, LAKS, BUSS, BELL, MANS}   \n",
       "4           26202         {EMET, IA, NEPC, SHEWR, CUMB}   \n",
       "...           ...                                   ...   \n",
       "13631     7117863  {R2989, EW8677, R3574, R3683, R2414}   \n",
       "13632     7119649     {IA, R3668, MOOR, R100142, MOOR3}   \n",
       "13633     7120107      {EMET, IA, NEPC, R3683, NEPCSPA}   \n",
       "13634     7121658    {IA, MPNGWE, EW725, DRCASP, R3683}   \n",
       "13635     7122285   {R2047, R1287, R1731, R1544, R1873}   \n",
       "\n",
       "                            Set2_recommendation  \n",
       "0                {IA, CASB, R3683, R2826, SUNP}  \n",
       "1                                           NaN  \n",
       "2                                           NaN  \n",
       "3                                           NaN  \n",
       "4                  {IA, LAKS, BUSS, BELL, MANS}  \n",
       "...                                         ...  \n",
       "13631  {EW5623, EW7053, EW5856, EW3880, EW4445}  \n",
       "13632                   {EMET, BELL, IA, MOOR3}  \n",
       "13633          {EMET, R2395, BFRC, R2734, MGWC}  \n",
       "13634          {R0508, R0899, R0090, MIO, HILD}  \n",
       "13635     {R0579, R0397, R0889, R100269, R0745}  \n",
       "\n",
       "[13636 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_content_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dc3d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create content_recommendations table\n",
    "dt_content_recommendations.to_csv(loc + 'recommendations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a89f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call all functions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
